This project demonstrates the concept of Bias and Variance in Machine Learning.

Generates synthetic nonlinear data (sine curve + noise).

Trains three models:

Linear Regression → High Bias (Underfitting)

Decision Tree → High Variance (Overfitting)

Random Forest → Balanced (Good Fit)

Plots predictions of each model against the true function to visualize underfitting, overfitting, and balanced fitting.

Computes MSE to numerically show the effect of bias and variance on model error.

Technologies Used:

Python 3

NumPy

Matplotlib

scikit-learn

Learning Outcome:
Understand the Bias–Variance Tradeoff, and how model complexity affects generalization.